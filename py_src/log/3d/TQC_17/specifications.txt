train.py / saved_model / env = fr3() / 0726 17:52

ë§¤ 5hz ë§ˆë‹¤ action ìƒì„± 
pre train ì‚¬ìš© ì•ˆí•˜ê³ , 
self.stack = 5
6ê°€ì§€ handle case  + clock / counter clock ë‘˜ ë‹¤. 
clssifier ì´ìš©í•´ì„œ ìž¡ì•„ì•¼ í•˜ëŠ” ìœ„ì¹˜ ì„ ì •

obeservationì— ìž¡ëŠ” ìœ„ì¹˜, ë°©í–¥, ê·¸ë¦¬ê³  qê°’ì´ ì¶”ê°€ë¨ 

ðŸ˜˜ï¸objectë¥¼ 6ê°œ í›„ë³´êµ°(rotation ë°©í–¥ë„ 2ê°€ì§€) ì—ì„œ random ì„ ì¶”ê°€ í•´ ì¤Œ!!(robustness) random ë²”ìœ„ë¥¼ ëŠ˜ë ¤ì¤Œ
handle + valve!!
controller x_kp = 0, drpy -> gradually increased, gripper splitìœ¼ë¡œ!
operational space control ì¶”ê°€ í•´ ì¤¬ê³ , next rpy ìž˜ëª» ë§Œë“œëŠ”ê±° ìˆ˜ì •í•´ì¤¬ë‹¤!!!!!!!!!
ðŸ˜˜ï¸ gripper close = 0.01, 0.0095 


 observation = dict(object=self.obs_object,  # [self.model.body_pos[bid], obj_rotation6d, [result.item()/36], [direction]]
 		     q=self.obs_q, 
 		     rpy=self.obs_rpy, 
 		     rpy_des=self.obs_rpy_des, 
 		     x_plan=self.obs_xyzdes,
 		     x_pos=self.obs_xyz)

result.item() -> classifier output 0~35 ì‚¬ì´ ì˜ ê°’!


reward done -> contact /  bound ë‚˜ëˆ„ì–´ì¤Œ. ì¶©ëŒì´ ë” ì•ˆì¢‹ê²Œ í‰ê°€ë˜ê¸° ìœ„í•¨
self.rw_acc = 1  # np.exp(-sum(abs(action - self.action_pre)))
self.rw_xyz = 0.1  # np.exp(-2*sum(abs(self.obs_xyz[0] - self.obs_xyzdes[0])))
self.rw_t = 1  # time done -> reward_time = 1
self.rw_c = 10  # contact done -> -1
self.rw_b = 0.5  # joint boundary done -> -1
self.rw_gr = 1.5  # 1/-1 grasp
self.rw_rpy = 0.5 # np.exp(-2*sum(abs(rotations.subtract_euler(self.obs_rpy_des, self.obs_rpy))[0]))
contactí•˜ëŠ” íŒŒíŠ¸ë¥¼ ìª¼ê°œì¤Œ
